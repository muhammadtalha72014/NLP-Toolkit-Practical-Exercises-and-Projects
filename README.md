# NLP-Toolkit-Practical-Exercises-and-Projects

This repository contains my practice work and exercises based on the YouTube Codebasics NLP playlist. The aim of this repository is to document my learning journey in NLP, covering a range of fundamental topics and culminating in a project that applies these concepts.

# Topics Covered
## 1. Regular Expressions
- Learning how to use regular expressions for pattern matching in text.
- Examples include finding specific patterns, extracting substrings, and validating string formats.

## 2. NLP Pipeline
- Understanding the typical NLP pipeline, including data collection, text preprocessing, feature extraction, model building, and evaluation.
- Implementation of a simple NLP pipeline for text analysis.

## 3. Spacy vs NLTK
- Comparing two popular NLP libraries: Spacy and NLTK.
- Evaluating their strengths and weaknesses, and learning how to use each for different NLP tasks.

## 4. Tokenization
- Breaking down text into individual tokens (words or sentences).
- Exploring different tokenization techniques provided by Spacy and NLTK.

## 5. Stemming and Lemmatization
- Understanding the difference between stemming and lemmatization.
- Implementing these techniques to reduce words to their base or root form.

## 6. Parts of Speech (POS) Tagging
- Assigning parts of speech to each token in a text.
- Using Spacy and NLTK to perform POS tagging and understanding its applications.

## 7. Named Entity Recognition (NER)
- Identifying and classifying named entities (e.g., people, organizations, dates) in text.
- Practicing NER with Spacy to extract meaningful information from text.

## 8. Label Encoding & One-Hot Encoding
- Converting categorical data into numerical format using label encoding and one-hot encoding.
- Applying these techniques in the context of NLP to prepare text data for machine learning models.

## 9. Bag of Words
- Representing text data as a bag of words (BoW) model.
- Implementing BoW for text classification tasks and understanding its limitations.

## 10. Stop Words
- Removing common words that do not contribute much to the meaning of a sentence.
- Creating custom stop words lists and using built-in lists from NLP libraries.

## 11. Bag of n-Grams
- Extending the BoW model to consider n-grams (contiguous sequences of n words).
- Understanding how n-grams capture more context compared to individual words.

## 12. TF-IDF
- Implementing Term Frequency-Inverse Document Frequency (TF-IDF) to weigh the importance of words in a document.
- Using TF-IDF for text analysis and classification tasks.

## 13. Word Embeddings
- Learning about word embeddings like Word2Vec and GloVe.
- Implementing word embeddings to capture semantic relationships between words.

# Usage
You can find the Jupyter notebooks for each topic in the notebooks directory. Each notebook contains detailed explanations and code examples for the respective topic.
